{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datas ###\n",
    "#to_be_matched = [ \"BATCH_REFERENCE\", \"TRANSACTION_REFERENCE\",\"BUYER_NAME\", \"SUPPLIER_NAME\" , \"INVOICE_REFERENCE\", \"PO_REFERENCE\",\n",
    "#                    \"INVOICE_DATE\", \"INVOICE_AMOUNT\", \"INVOICE_CURRENCY\", \"MATURITY_DATE\", \"PAYMENT_DATE\", \"TENOR\", \"NET_AMOUNT\",\n",
    "#                   \"GROSS_AMOUNT\", \"DISCOUNT_AMOUNT\", \"ADJUSTMENT_AMOUNT\", \"ADJUSTMENT_REASON_CODE\",\"PAYMENT_TERM\", \"STATUS\", \"NOTES\"]\n",
    "\n",
    "#to_be_matched = [ \"Batch #\", \"Transaction #\", \"Buyer Name\", \"Supplier Name\", \"Inv #\", \"PO #\", \n",
    "#\"Invoice Date\", \"Invoice Amount\", \"Invoice Currency\", \"Maturity Date\", \"Payment Date\", \"Tenor\", \"Net Amount\", \"Gross Amount\", \"Discount Amount\", \"Adjustment Amount\", \"Adjustment Reason Code\", \"Payment Term\", \"Status\", \"Notes\"]\n",
    "\n",
    "to_be_matched = [\"batchNum\", \"txnNum\", \"buyer\", \"supplier\", \"invNum\", \"poNum\", \"invDt\", \"invAmt\", \"invCcy\", \"matDt\", \"payDueDt\", \"tenor\", \"netAmt\", \"grossAmt\", \"discAmt\", \"adjustAmt\", \"adjustReason\", \"payTerm\", \"status\", \"notes\"]\n",
    "\n",
    "target = [ \"batchReference\", \"transactionReference\", \"buyerName\", \n",
    "            \"supplierName\", \"invoiceReference\", \"poReference\", \n",
    "            \"invoiceDate\", \"invoiceAmount\", \"invoiceCurrency\", \"maturityDate\", \n",
    "            \"paymentDate\", \"tenor\", \"netAmount\", \"grossAmount\", \n",
    "            \"discountAmount\", \"adjustmentAmount\", \"adjustmentReasonCode\", \"paymentTerm\", \"status\", \"notes\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({\"to_be_matched\":to_be_matched,\"target\":target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to_be_matched</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchNum</td>\n",
       "      <td>batchReference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txnNum</td>\n",
       "      <td>transactionReference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>buyerName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supplier</td>\n",
       "      <td>supplierName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invNum</td>\n",
       "      <td>invoiceReference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  to_be_matched                target\n",
       "0      batchNum        batchReference\n",
       "1        txnNum  transactionReference\n",
       "2         buyer             buyerName\n",
       "3      supplier          supplierName\n",
       "4        invNum      invoiceReference"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         batchnum\n",
       "1           txnnum\n",
       "2            buyer\n",
       "3         supplier\n",
       "4           invnum\n",
       "5            ponum\n",
       "6            invdt\n",
       "7           invamt\n",
       "8           invccy\n",
       "9            matdt\n",
       "10        payduedt\n",
       "11           tenor\n",
       "12          netamt\n",
       "13        grossamt\n",
       "14         discamt\n",
       "15       adjustamt\n",
       "16    adjustreason\n",
       "17         payterm\n",
       "18          status\n",
       "19           notes\n",
       "Name: to_be_matched, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning the to be matched column ###\n",
    "def clean_strings(string):\n",
    "    string = re.sub('[^a-zA-Z0-9.?]',' ',string)\n",
    "    string = string.replace(' ','').lstrip().rstrip()\n",
    "    return string.lower()\n",
    "\n",
    "dataset[\"to_be_matched\"].apply(clean_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4285714285714286,\n",
       " 0.15000000000000002,\n",
       " 0.5555555555555556,\n",
       " 0.6666666666666667,\n",
       " 0.25,\n",
       " 0.2727272727272727,\n",
       " 0.4545454545454546,\n",
       " 0.46153846153846156,\n",
       " 0.4,\n",
       " 0.41666666666666663,\n",
       " 0.4545454545454546,\n",
       " 1.0,\n",
       " 0.6666666666666667,\n",
       " 0.7272727272727273,\n",
       " 0.5,\n",
       " 0.5625,\n",
       " 0.6,\n",
       " 0.6363636363636364,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "def levenshtein_rate(product1, product2):\n",
    "    distance = levenshtein(product1, product2)\n",
    "    max_len = max(len(product1), len(product2))\n",
    "    return 1 - (distance / max_len)\n",
    "\n",
    "score_list = [levenshtein_rate(list(dataset[\"to_be_matched\"].apply(clean_strings))[i],list(dataset[\"target\"].apply(clean_strings))[i]) for i in range(0,len(dataset[\"to_be_matched\"]))]\n",
    "#score_list = [levenshtein_rate(list(dataset[\"to_be_matched\"])[i],list(dataset[\"target\"])[i]) for i in range(0,len(dataset[\"to_be_matched\"]))]\n",
    "#round(sum(score_list)/len(score_list),2)\n",
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eroynab\\Documents\\Anaconda\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[55,\n",
       " 23,\n",
       " 71,\n",
       " 80,\n",
       " 36,\n",
       " 38,\n",
       " 62,\n",
       " 63,\n",
       " 57,\n",
       " 59,\n",
       " 53,\n",
       " 100,\n",
       " 80,\n",
       " 84,\n",
       " 67,\n",
       " 72,\n",
       " 75,\n",
       " 78,\n",
       " 100,\n",
       " 100]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "fuzz_socre = [fuzz.token_sort_ratio(list(dataset[\"to_be_matched\"].apply(clean_strings))[i],list(dataset[\"target\"].apply(clean_strings))[i]) for i in range(0,len(dataset[\"to_be_matched\"]))] \n",
    "\n",
    "fuzz_socre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62,\n",
       " 33,\n",
       " 100,\n",
       " 100,\n",
       " 50,\n",
       " 40,\n",
       " 60,\n",
       " 50,\n",
       " 67,\n",
       " 60,\n",
       " 50,\n",
       " 100,\n",
       " 83,\n",
       " 88,\n",
       " 57,\n",
       " 78,\n",
       " 67,\n",
       " 57,\n",
       " 100,\n",
       " 100]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz_socre_abb = [fuzz.partial_token_sort_ratio(list(dataset[\"to_be_matched\"].apply(clean_strings))[i],list(dataset[\"target\"].apply(clean_strings))[i]) for i in range(0,len(dataset[\"to_be_matched\"]))] \n",
    "fuzz_socre_abb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "def ngrams(string, n=2):\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "#vectorizer = TfidfVectorizer(analyzer=ngrams)\n",
    "vectorizer = pickle.load(open(\"vect.sav\",\"rb\"))\n",
    "\n",
    "def cosine_sim(text1, text2, vect):\n",
    "    #vectorizer = TfidfVectorizer(analyzer=ngrams)\n",
    "    #vectorizer = pickle.load(open(\"vect.sav\",\"rb\"))\n",
    "    tfidf = vect.transform([text1, text2])\n",
    "    pickle.dump(vect,open(\"vect.sav\",\"wb\"))\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ba', 'at', 'tc', 'ch', 'hr', 're', 'ef', 'fe', 'er', 're', 'en', 'nc', 'ce']\n"
     ]
    }
   ],
   "source": [
    "print(ngrams(list(dataset[\"to_be_matched\"].apply(clean_strings))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_score = [cosine_sim(list(dataset[\"to_be_matched\"].apply(clean_strings)),list(dataset[\"target\"].apply(clean_strings)),vectorizer) for i in range(0,len(dataset[\"to_be_matched\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"vect.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.42.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.22.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.5.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\eroynab\\documents\\anaconda\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.2.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047114 sha256=7e74e92de3863eb24073cdbd1c2b80292ec02f9b3bba29c1dd1d334649ca174e\n",
      "  Stored in directory: C:\\Users\\eroynab\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-fbnmr_9f\\wheels\\b7\\0d\\f0\\7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.3.1\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-475f5c7c533f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' python -m spacy download en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdoc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'batchreference'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc1 = nlp(u'batchreference')\n",
    "doc2 = nlp(u'BATCH_REFERENCE')\n",
    "\n",
    "#print doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2979752358504139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eroynab\\Documents\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc1 = nlp(u'batchreference')\n",
    "doc2 = nlp(u'BATCH_REFERENCE')\n",
    "\n",
    "print (doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [list(dataset[\"to_be_matched\"].apply(clean_strings)),list(dataset[\"target\"].apply(clean_strings))]\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "model.similarity('batchreference', clean_strings('BATCH#'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Starting fresh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the data to train your model on ##\n",
    "target = [ \"batchReference\", \"transactionReference\", \"buyerName\", \n",
    "            \"supplierName\", \"invoiceReference\", \"poReference\", \n",
    "            \"invoiceDate\", \"invoiceAmount\", \"invoiceCurrency\", \"maturityDate\", \n",
    "            \"paymentDate\", \"tenor\", \"netAmount\", \"grossAmount\", \n",
    "            \"discountAmount\", \"adjustmentAmount\", \"adjustmentReasonCode\", \"paymentTerm\", \"status\", \"notes\"]\n",
    "\n",
    "source_1 = [\"BATCH_REF\", \"TXN_REF\", \"BUYER\", \"SUPPLIER\", \"INV_REF\", \"PO_REF\", \"INV_DATE\", \"INV_AMT\", \"INV_CCY\", \"MAT_DATE\", \"PAY_DATE\", \"TENOR\", \"NET_AMT\", \"GROSS_AMT\", \"DISC_AMT\", \"ADJUST_AMT\", \"ADJUST_REASON_CODE\", \"PAY_TERM\", \"STATUS\", \"NOTE\" ]\n",
    "source_2 = [\"batchNum\", \"txnNum\", \"buyer\", \"supplier\", \"invNum\", \"poNum\", \"invDt\", \"invAmt\", \"invCcy\", \"matDt\", \"payDueDt\", \"tenor\", \"netAmt\", \"grossAmt\", \"discAmt\", \"adjustAmt\", \"adjustReason\", \"payTerm\", \"status\", \"notes\"]\n",
    "source_3 = [ \"BATCH_REFERENCE\", \"TRANSACTION_REFERENCE\",\"BUYER_NAME\", \"SUPPLIER_NAME\" , \"INVOICE_REFERENCE\", \"PO_REFERENCE\",\n",
    "                    \"INVOICE_DATE\", \"INVOICE_AMOUNT\", \"INVOICE_CURRENCY\", \"MATURITY_DATE\", \"PAYMENT_DATE\", \"TENOR\", \"NET_AMOUNT\",\n",
    "                   \"GROSS_AMOUNT\", \"DISCOUNT_AMOUNT\", \"ADJUSTMENT_AMOUNT\", \"ADJUSTMENT_REASON_CODE\",\"PAYMENT_TERM\", \"STATUS\", \"NOTES\"]\n",
    "source_4 = [\"BatchNumber\", \"TransactionNumber\", \"Buyer\", \"Supplier\", \"InvoiceNumber\", \"PONumber\", \"InvoiceDate\", \"InvoiceAmount\", \"InvoiceCurrency\", \"MaturityDate\", \"PaymentDate\", \"Tenor\", \"NetAmt\", \"GrossAmt\", \"DiscountAmt\", \"AdjustmAmt\", \"AdjustReasonCode\", \"PayTerm\", \"Status\", \"Notes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create your dataset ###\n",
    "### Ideal Mappings ###\n",
    "dataset = pd.DataFrame({\"source_format\":source_1+source_2+source_3+source_4,\"target_format\":target+target+target+target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_format</th>\n",
       "      <th>target_format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>supplier</td>\n",
       "      <td>supplierName</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NOTE</td>\n",
       "      <td>notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAT_DATE</td>\n",
       "      <td>maturityDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>notes</td>\n",
       "      <td>notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NET_AMOUNT</td>\n",
       "      <td>netAmount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AdjustmAmt</td>\n",
       "      <td>adjustmentAmount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PONumber</td>\n",
       "      <td>poReference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tenor</td>\n",
       "      <td>tenor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ADJUSTMENT_REASON_CODE</td>\n",
       "      <td>adjustmentReasonCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>PayTerm</td>\n",
       "      <td>paymentTerm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_format         target_format\n",
       "23                supplier          supplierName\n",
       "19                    NOTE                 notes\n",
       "9                 MAT_DATE          maturityDate\n",
       "39                   notes                 notes\n",
       "52              NET_AMOUNT             netAmount\n",
       "..                     ...                   ...\n",
       "75              AdjustmAmt      adjustmentAmount\n",
       "65                PONumber           poReference\n",
       "31                   tenor                 tenor\n",
       "56  ADJUSTMENT_REASON_CODE  adjustmentReasonCode\n",
       "77                 PayTerm           paymentTerm\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_ordered_dataset = dataset.sample(frac=1)\n",
    "shuffled_ordered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = dataset.append(shuffled_ordered_dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Non-Ideal Mappings ###\n",
    "from random import shuffle\n",
    "\n",
    "source_final_list = source_1+source_2+source_3+source_4\n",
    "target_final_list = target+target+target+target\n",
    "shuffle(source_final_list)\n",
    "#print(source_final_list)\n",
    "\n",
    "#dataset[\"source_format\"] = list(dataset[\"source_format\"]) + source_final_list\n",
    "#dataset[\"target_format\"] = list(dataset[\"target_format\"]) + target_final_list\n",
    "\n",
    "#dataset = dataset.append(pd.DataFrame([list(source_final_list),list(target_final_list)],columns=dataset.columns))\n",
    "#dataset[\"target_format\"] = dataset[\"target_format\"].append(pd.Series(target_final_list,index=\"target_format\"))\n",
    "shuffled_df = pd.DataFrame({\"source_format\":list(source_final_list),\"target_format\":list(target_final_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.append(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 2)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the cleaned string for all ###\n",
    "def clean_strings(string):\n",
    "    string = re.sub('[^a-zA-Z0-9.?]',' ',string)\n",
    "    string = string.replace(' ','').lstrip().rstrip()\n",
    "    return string.lower()\n",
    "\n",
    "dataset[\"source_format\"] = dataset[\"source_format\"].apply(clean_strings)\n",
    "dataset[\"target_format\"] = dataset[\"target_format\"].apply(clean_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = [round(levenshtein_rate(list(dataset[\"source_format\"])[i],list(dataset[\"target_format\"])[i]),2) * 100 for i in range(0,len(dataset[\"source_format\"]))]\n",
    "\n",
    "dataset[\"lev_score\"] = score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_format</th>\n",
       "      <th>target_format</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>fuzz_lev_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchref</td>\n",
       "      <td>batchreference</td>\n",
       "      <td>57.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txnref</td>\n",
       "      <td>transactionreference</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>buyername</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supplier</td>\n",
       "      <td>suppliername</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invref</td>\n",
       "      <td>invoicereference</td>\n",
       "      <td>38.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>buyer</td>\n",
       "      <td>adjustmentamount</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>transactionnumber</td>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>paymentterm</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>adjustreasoncode</td>\n",
       "      <td>status</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>notes</td>\n",
       "      <td>notes</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source_format         target_format  lev_score  fuzz_lev_score\n",
       "0               batchref        batchreference       57.0              73\n",
       "1                 txnref  transactionreference       25.0              38\n",
       "2                  buyer             buyername       56.0              71\n",
       "3               supplier          suppliername       67.0              80\n",
       "4                 invref      invoicereference       38.0              55\n",
       "..                   ...                   ...        ...             ...\n",
       "75                 buyer      adjustmentamount       12.0              19\n",
       "76     transactionnumber  adjustmentreasoncode       15.0              38\n",
       "77  adjustmentreasoncode           paymentterm       25.0              39\n",
       "78      adjustreasoncode                status       19.0              27\n",
       "79                 notes                 notes      100.0             100\n",
       "\n",
       "[640 rows x 4 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz_lev_score = [fuzz.token_sort_ratio(list(dataset[\"source_format\"])[i],list(dataset[\"target_format\"])[i]) for i in range(0,len(dataset[\"source_format\"]))]\n",
    "\n",
    "dataset[\"fuzz_lev_score\"] = fuzz_lev_score\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_format</th>\n",
       "      <th>target_format</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>fuzz_lev_score</th>\n",
       "      <th>fuzz_abb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchref</td>\n",
       "      <td>batchreference</td>\n",
       "      <td>57.0</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txnref</td>\n",
       "      <td>transactionreference</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>buyername</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supplier</td>\n",
       "      <td>suppliername</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invref</td>\n",
       "      <td>invoicereference</td>\n",
       "      <td>38.0</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>buyer</td>\n",
       "      <td>adjustmentamount</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>transactionnumber</td>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>paymentterm</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>adjustreasoncode</td>\n",
       "      <td>status</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>notes</td>\n",
       "      <td>notes</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source_format         target_format  lev_score  fuzz_lev_score  \\\n",
       "0               batchref        batchreference       57.0              73   \n",
       "1                 txnref  transactionreference       25.0              38   \n",
       "2                  buyer             buyername       56.0              71   \n",
       "3               supplier          suppliername       67.0              80   \n",
       "4                 invref      invoicereference       38.0              55   \n",
       "..                   ...                   ...        ...             ...   \n",
       "75                 buyer      adjustmentamount       12.0              19   \n",
       "76     transactionnumber  adjustmentreasoncode       15.0              38   \n",
       "77  adjustmentreasoncode           paymentterm       25.0              39   \n",
       "78      adjustreasoncode                status       19.0              27   \n",
       "79                 notes                 notes      100.0             100   \n",
       "\n",
       "    fuzz_abb_score  \n",
       "0              100  \n",
       "1               67  \n",
       "2              100  \n",
       "3              100  \n",
       "4               67  \n",
       "..             ...  \n",
       "75              20  \n",
       "76              50  \n",
       "77              55  \n",
       "78              67  \n",
       "79             100  \n",
       "\n",
       "[640 rows x 5 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz_abb_score = [fuzz.partial_token_sort_ratio(list(dataset[\"source_format\"])[i],list(dataset[\"target_format\"])[i]) for i in range(0,len(dataset[\"source_format\"]))]\n",
    "\n",
    "dataset[\"fuzz_abb_score\"] = fuzz_abb_score\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "def ngrams(string, n=2):\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "#vectorizer = TfidfVectorizer(analyzer=ngrams)\n",
    "vectorizer = pickle.load(open(\"vect.sav\",\"rb\"))\n",
    "\n",
    "def cosine_sim(text1, text2, vect):\n",
    "    #vectorizer = TfidfVectorizer(analyzer=ngrams)\n",
    "    #vectorizer = pickle.load(open(\"vect.sav\",\"rb\"))\n",
    "    tfidf = vect.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "vect_score = [round(cosine_sim(list(dataset[\"source_format\"])[i],list(dataset[\"target_format\"])[i],vectorizer),2)*100 for i in range(0,len(dataset[\"source_format\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer,open(\"vect.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"vect_score\"] = vect_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 6)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"match\"] = [1 if i < 320 else 0 for i in range(0,dataset.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"trainer.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_format</th>\n",
       "      <th>target_format</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>fuzz_lev_score</th>\n",
       "      <th>fuzz_abb_score</th>\n",
       "      <th>vect_score</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batchref</td>\n",
       "      <td>batchreference</td>\n",
       "      <td>57.0</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txnref</td>\n",
       "      <td>transactionreference</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>buyer</td>\n",
       "      <td>buyername</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supplier</td>\n",
       "      <td>suppliername</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invref</td>\n",
       "      <td>invoicereference</td>\n",
       "      <td>38.0</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>buyer</td>\n",
       "      <td>adjustmentamount</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>transactionnumber</td>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>adjustmentreasoncode</td>\n",
       "      <td>paymentterm</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>adjustreasoncode</td>\n",
       "      <td>status</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27</td>\n",
       "      <td>67</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>notes</td>\n",
       "      <td>notes</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source_format         target_format  lev_score  fuzz_lev_score  \\\n",
       "0               batchref        batchreference       57.0              73   \n",
       "1                 txnref  transactionreference       25.0              38   \n",
       "2                  buyer             buyername       56.0              71   \n",
       "3               supplier          suppliername       67.0              80   \n",
       "4                 invref      invoicereference       38.0              55   \n",
       "..                   ...                   ...        ...             ...   \n",
       "75                 buyer      adjustmentamount       12.0              19   \n",
       "76     transactionnumber  adjustmentreasoncode       15.0              38   \n",
       "77  adjustmentreasoncode           paymentterm       25.0              39   \n",
       "78      adjustreasoncode                status       19.0              27   \n",
       "79                 notes                 notes      100.0             100   \n",
       "\n",
       "    fuzz_abb_score  vect_score  match  \n",
       "0              100        68.0      1  \n",
       "1               67        25.0      1  \n",
       "2              100        58.0      1  \n",
       "3              100        69.0      1  \n",
       "4               67        35.0      1  \n",
       "..             ...         ...    ...  \n",
       "75              20         0.0      0  \n",
       "76              50         6.0      0  \n",
       "77              55        12.0      0  \n",
       "78              67        14.0      0  \n",
       "79             100       100.0      0  \n",
       "\n",
       "[640 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_format', 'target_format', 'lev_score', 'fuzz_lev_score',\n",
       "       'fuzz_abb_score', 'vect_score', 'match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 7)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPlitting for train test set ####\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset[['lev_score', 'fuzz_lev_score','fuzz_abb_score', 'vect_score']]\n",
    "y = dataset[\"match\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        97\n",
      "           1       0.94      1.00      0.97       115\n",
      "\n",
      "    accuracy                           0.97       212\n",
      "   macro avg       0.97      0.96      0.97       212\n",
      "weighted avg       0.97      0.97      0.97       212\n",
      "\n",
      "############################################\n",
      "[[ 90   7]\n",
      " [  0 115]]\n",
      "############################################\n",
      "0.9669811320754716\n",
      "############################################\n",
      "0.9668507522860634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score,accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "dt_mod = DecisionTreeClassifier()\n",
    "dt_mod.fit(X_train,y_train)\n",
    "\n",
    "preds = dt_mod.predict(X_test)\n",
    "\n",
    "print(\"############################################\")\n",
    "print(classification_report(y_test,preds))\n",
    "print(\"############################################\")\n",
    "print(confusion_matrix(y_test,preds))\n",
    "print(\"############################################\")\n",
    "print(accuracy_score(y_test,preds))\n",
    "print(\"############################################\")\n",
    "print(f1_score(y_test,preds,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        97\n",
      "           1       0.93      0.95      0.94       115\n",
      "\n",
      "    accuracy                           0.93       212\n",
      "   macro avg       0.93      0.93      0.93       212\n",
      "weighted avg       0.93      0.93      0.93       212\n",
      "\n",
      "############################################\n",
      "[[ 89   8]\n",
      " [  6 109]]\n",
      "############################################\n",
      "0.9339622641509434\n",
      "############################################\n",
      "0.9339029630232053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(20, 20, 20), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
    "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
    "       verbose=False, warm_start=False)\n",
    "\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "mlp_preds = mlp.predict(X_test)\n",
    "\n",
    "print(\"############################################\")\n",
    "print(classification_report(y_test,mlp_preds))\n",
    "print(\"############################################\")\n",
    "print(confusion_matrix(y_test,mlp_preds))\n",
    "print(\"############################################\")\n",
    "print(accuracy_score(y_test,mlp_preds))\n",
    "print(\"############################################\")\n",
    "print(f1_score(y_test,mlp_preds,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9156626506024096\n",
      "10    0\n",
      "37    1\n",
      "57    1\n",
      "37    0\n",
      "38    1\n",
      "     ..\n",
      "23    1\n",
      "75    1\n",
      "30    0\n",
      "72    1\n",
      "26    0\n",
      "Name: match, Length: 212, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mlp_preds = dt_mod.predict_proba(X_test)\n",
    "print(mlp_preds[2][1]) ###2nd column\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_mod.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "###save dt mod ###\n",
    "pickle.dump(dt_mod,open(\"decision_tree.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mlp,open(\"mlp.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
